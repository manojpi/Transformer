{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "context_length = 36\n",
    "embedding_dim = 72\n",
    "num_heads = 6\n",
    "head_dim = embedding_dim // num_heads\n",
    "num_layers = 6\n",
    "dropout=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_dim, mask=False, cross_head = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        self.query = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        self.mask = mask\n",
    "\n",
    "        if self.mask:\n",
    "            self.register_buffer(\"tril\", torch.tril(torch.ones(context_length, context_length)))\n",
    "    \n",
    "    def forward(self, embeddings, encoder_embeddings = None):\n",
    "\n",
    "        B, T, C = embeddings.shape\n",
    "\n",
    "        key = self.key(encoder_embeddings) if encoder_embeddings is not None else self.key(embeddings)\n",
    "        value = self.value(encoder_embeddings)  if encoder_embeddings is not None else self.value(embeddings)\n",
    "        query = self.query(embeddings)\n",
    "\n",
    "        wei = query @ key.transpose(-2, -1) * C ** -0.5\n",
    "        if self.mask:\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
    "        \n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        value = self.value(embeddings)\n",
    "        output = wei @ value\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.heads = nn.ModuleList([Head(head_dim, mask=True) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "\n",
    "        output = torch.concat([head(embeddings) for head in self.heads], dim=-1)\n",
    "        output = self.dropout(self.proj(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiCrossHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.heads = nn.ModuleList([Head(head_dim) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, embeddings, encoder_embeddings):\n",
    "\n",
    "        output = torch.concat([head(embeddings, encoder_embeddings) for head in self.heads], dim=-1)\n",
    "        output = self.dropout(self.proj(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        return self.ffn(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, head_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_mha = MultiHeadAttention(num_heads, head_dim)\n",
    "        self.cross_mha = MultiCrossHeadAttention(num_heads, head_dim)\n",
    "        self.ffwd = FeedForward(embedding_dim)\n",
    "        self.ln1 = nn.LayerNorm(embedding_dim)\n",
    "        self.ln2 = nn.LayerNorm(embedding_dim)\n",
    "        self.ln3 = nn.LayerNorm(embedding_dim)\n",
    "    \n",
    "    def forward(self, embeddings, encoder_embeddings):\n",
    "\n",
    "        output = embeddings + self.ln1(self.self_mha(embeddings))\n",
    "        output = output + self.ln2(self.cross_mha(output, encoder_embeddings))\n",
    "        output = output + self.ln3(self.ffwd(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2106, -0.1051,  1.0015,  ..., -0.0353,  2.1705, -3.4710],\n",
       "         [-3.2287, -0.9642,  0.4708,  ...,  0.8362,  2.0187,  1.5654],\n",
       "         [ 2.1574, -0.8670, -0.5740,  ...,  4.6818,  4.9625, -1.6910],\n",
       "         ...,\n",
       "         [-1.0304,  0.0716, -0.9657,  ...,  0.9160,  4.8802,  1.8321],\n",
       "         [-1.1211,  0.2472,  0.6258,  ..., -1.1739,  3.9222,  0.7250],\n",
       "         [-1.5589, -1.0994, -1.1518,  ...,  0.7450,  2.0824, -1.5496]],\n",
       "\n",
       "        [[ 0.6546, -0.0282, -1.4039,  ..., -1.3663,  0.7442,  0.0474],\n",
       "         [-0.4554, -0.8557, -2.5814,  ...,  1.0194,  1.5900, -0.5650],\n",
       "         [-0.7117,  1.2064, -0.0846,  ..., -1.2891,  0.2806, -0.4523],\n",
       "         ...,\n",
       "         [-1.7036, -2.1728, -1.6704,  ..., -4.3779, -2.0408, -1.6914],\n",
       "         [ 1.1053,  1.1844, -2.1042,  ..., -0.5678,  0.7903, -1.7722],\n",
       "         [ 1.0782, -0.7808, -0.1235,  ..., -4.1783,  1.4987, -0.1619]],\n",
       "\n",
       "        [[-2.6997, -1.7621, -0.6285,  ...,  2.2566,  3.1865,  0.9203],\n",
       "         [-2.3394, -0.5988,  0.0254,  ..., -1.0415,  1.8708,  1.2763],\n",
       "         [-1.2558,  1.2644, -1.5743,  ...,  2.4422,  3.6276,  0.9805],\n",
       "         ...,\n",
       "         [-0.0058,  1.3676, -1.3575,  ..., -1.1736,  1.1175, -0.2724],\n",
       "         [-0.4415,  1.5662, -4.3122,  ...,  1.0164,  0.0768,  0.4606],\n",
       "         [-1.7135, -2.1741, -1.1851,  ...,  0.3317,  3.2204, -0.4660]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.0094, -1.8826, -0.3139,  ...,  0.4010,  1.4344,  3.6535],\n",
       "         [-1.7747, -3.9846,  1.1324,  ..., -2.9105,  0.9437,  2.3696],\n",
       "         [ 3.0456, -1.1150,  2.5977,  ...,  0.8391,  4.8515, -0.4816],\n",
       "         ...,\n",
       "         [-0.1493, -3.2485, -0.1834,  ...,  3.2091,  3.1626,  1.2475],\n",
       "         [ 0.5360,  0.5512, -1.9252,  ...,  2.3859,  1.8936,  0.4270],\n",
       "         [-1.5940, -1.2595, -1.6244,  ..., -1.1202,  3.6280,  1.3195]],\n",
       "\n",
       "        [[ 2.7076, -0.9171, -1.0707,  ..., -1.2123,  2.0839, -0.3436],\n",
       "         [-0.3964, -3.0109,  1.7929,  ..., -1.5272,  3.6812, -1.3648],\n",
       "         [ 1.3678, -1.8439, -1.8465,  ..., -2.0967,  0.5164, -1.6923],\n",
       "         ...,\n",
       "         [-2.0073, -0.1398, -1.8925,  ..., -1.4534,  0.1891,  0.8924],\n",
       "         [-1.4787, -0.4687, -2.4226,  ...,  0.2674,  2.7598, -1.4940],\n",
       "         [-0.7597, -0.0308, -1.8923,  ..., -2.0281,  1.3972, -0.5490]],\n",
       "\n",
       "        [[-0.9310, -1.3687, -0.8310,  ...,  2.0603,  3.3686,  0.7516],\n",
       "         [-0.7971, -0.6804, -1.8622,  ...,  1.4531,  3.9873, -0.3744],\n",
       "         [-0.4610, -0.1061,  1.4800,  ...,  2.9932,  3.3915, -0.2931],\n",
       "         ...,\n",
       "         [-1.1368, -1.5795,  0.0788,  ..., -0.2552,  2.7133, -1.5849],\n",
       "         [-0.6345, -2.9988, -1.0512,  ..., -1.1961,  1.0305,  0.0206],\n",
       "         [-0.7958, -2.7291, -0.3054,  ...,  1.4195,  3.5126, -1.4473]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(mean=0.0, std=1.0, size=(batch_size, context_length, embedding_dim))\n",
    "y = torch.normal(mean=0.0, std=5.0, size=(batch_size, context_length, embedding_dim))\n",
    "decoder = Decoder(head_dim, embedding_dim)\n",
    "output = decoder(x, y)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-fall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
